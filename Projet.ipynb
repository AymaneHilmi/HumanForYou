{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age : Integer (Années)\n",
    "# Attrition : Boolean\n",
    "# BusinessTravel : Categorical (Non-Travel, Travel_Rarely, Travel_Frequently)\n",
    "# DistanceFromHome : Integer (km)\n",
    "# Education : Categorical (Avant College, College, Bachelor, Master, PhD)\n",
    "# EducationField : Categorical (Domaines d’étude)\n",
    "# EmployeeId : Integer (Identifiant unique)\n",
    "# Gender : Boolean (Homme/Femme)\n",
    "# JobLevel : Integer (1-5, niveau hiérarchique)\n",
    "# JobRole : Categorical (Intitulé des postes)\n",
    "# MaritalStatus : Categorical (Single, Married, Divorced)\n",
    "# MonthlyIncome : Float (Salaire mensuel)\n",
    "# NumCompaniesWorked : Integer (Nombre d’entreprises)\n",
    "# PercentSalaryHike : Float (Pourcentage)\n",
    "# StockOptionLevel : Integer (Niveau d’actions : 0, 1, 2, 3)\n",
    "# TotalWorkingYears : Integer (Années)\n",
    "# TrainingTimesLastYear : Integer (Jours)\n",
    "# YearsAtCompany : Integer (Années)\n",
    "# YearsSinceLastPromotion : Integer (Années)\n",
    "# YearsWithCurrentManager : Integer (Années)\n",
    "# JobInvolvement : Integer (1-4, Niveau d’implication)\n",
    "# PerformanceRating : Integer (1-4, Niveau de performance)\n",
    "# EnvironmentSatisfaction : Integer ou Null (1-4, Niveau de satisfaction, “NA” pour non-réponse)\n",
    "# JobSatisfaction : Integer ou Null (1-4, Niveau de satisfaction, “NA” pour non-réponse)\n",
    "# WorkLifeBalance : Integer ou Null (1-4, Niveau de satisfaction, “NA” pour non-réponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des bibliothèques principales\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder, OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import streamlit as st\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données\n",
    "hr_data = pd.read_csv('./data/general_data.csv')\n",
    "survey_data = pd.read_csv('./data/employee_survey_data.csv')\n",
    "manager_data = pd.read_csv('./data/manager_survey_data.csv')\n",
    "in_time_data = pd.read_csv('./data/in_time.csv')\n",
    "out_time_data = pd.read_csv('./data/out_time.csv')\n",
    "\n",
    "# Aperçu des données\n",
    "#print(in_time_data.head())\n",
    "#print(out_time_data.head())\n",
    "\n",
    "# Voir les donnees manquantes\n",
    "#print(hr_data.isnull().sum())\n",
    "#print(survey_data.isnull().sum())\n",
    "#print(manager_data.isnull().sum())\n",
    "\n",
    "# Supprimer la colonne EmployeeCount, StandardHours, Over18\n",
    "hr_data.drop(['EmployeeCount', 'StandardHours', 'Over18'], axis=1, inplace=True)\n",
    "\n",
    "# Supprimer les lignes pour NumCompaniesWorked vide \n",
    "hr_data.dropna(subset=['NumCompaniesWorked'], inplace=True)\n",
    "\n",
    "# Supprimer les lignes pour TotalWorkingYears vide\n",
    "hr_data.dropna(subset=['TotalWorkingYears'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renommer la première colonne pour qu'elle devienne \"EmployeeID\" dans in_time et out_time\n",
    "in_time_data.rename(columns={\"Unnamed: 0\": 'EmployeeID'}, inplace=True)\n",
    "out_time_data.rename(columns={\"Unnamed: 0\": 'EmployeeID'}, inplace=True)\n",
    "# Definir le format en date de toutes les colonnes (type) pour in_time et out_time sauf la colonne EmployeeID\n",
    "for col in in_time_data.columns[1:]:\n",
    "    in_time_data[col] = pd.to_datetime(in_time_data[col])\n",
    "\n",
    "for col in out_time_data.columns[1:]:\n",
    "    out_time_data[col] = pd.to_datetime(out_time_data[col])\n",
    "\n",
    "\n",
    "# Fusionner les données de chaque fichier\n",
    "hr_data = hr_data.merge(survey_data, on='EmployeeID')\n",
    "hr_data = hr_data.merge(manager_data, on='EmployeeID')\n",
    "\n",
    "#hr_data = hr_data.merge(in_time_data, on='EmployeeID')\n",
    "#hr_data = hr_data.merge(out_time_data, on='EmployeeID')\n",
    "\n",
    "# Moyenne sans decimales de EnvironmentSatisfaction, JobSatisfaction, WorkLifeBalance pour les valeurs manquantes\n",
    "hr_data['EnvironmentSatisfaction'].fillna(hr_data['EnvironmentSatisfaction'].median, inplace=True)\n",
    "hr_data['JobSatisfaction'].fillna(hr_data['JobSatisfaction'].median, inplace=True)\n",
    "hr_data['WorkLifeBalance'].fillna(hr_data['WorkLifeBalance'].median, inplace=True)\n",
    "\n",
    "# Definir le format de chaque colonne (type)\n",
    "hr_data['Age'] = hr_data['Age'].astype(int)\n",
    "hr_data['Attrition'] = hr_data['Attrition'].map({'Yes': 1, 'No': 0})\n",
    "hr_data['BusinessTravel'] = hr_data['BusinessTravel'].map({'Non-Travel': 0, 'Travel_Rarely': 1, 'Travel_Frequently': 2})\n",
    "hr_data['DistanceFromHome'] = hr_data['DistanceFromHome'].astype(int)\n",
    "hr_data['Education'] = hr_data['Education'].astype('category')\n",
    "hr_data['EducationField'] = hr_data['EducationField'].astype('category')\n",
    "hr_data['EmployeeID'] = hr_data['EmployeeID'].astype(int)\n",
    "hr_data['Gender'] = hr_data['Gender'].map({'Male': 1, 'Female': 0})\n",
    "hr_data['JobLevel'] = hr_data['JobLevel'].astype(int)\n",
    "hr_data['JobRole'] = hr_data['JobRole'].astype('category')\n",
    "hr_data['MaritalStatus'] = hr_data['MaritalStatus'].map({'Single': 0, 'Married': 1, 'Divorced': 2})\n",
    "hr_data['MonthlyIncome'] = hr_data['MonthlyIncome'].astype(float)\n",
    "hr_data['NumCompaniesWorked'] = hr_data['NumCompaniesWorked'].astype(int)\n",
    "hr_data['PercentSalaryHike'] = hr_data['PercentSalaryHike'].astype(float) / 100\n",
    "hr_data['StockOptionLevel'] = hr_data['StockOptionLevel'].astype(int)\n",
    "hr_data['TotalWorkingYears'] = hr_data['TotalWorkingYears'].astype(int)\n",
    "hr_data['TrainingTimesLastYear'] = hr_data['TrainingTimesLastYear'].astype(int)\n",
    "hr_data['YearsAtCompany'] = hr_data['YearsAtCompany'].astype(int)\n",
    "hr_data['YearsSinceLastPromotion'] = hr_data['YearsSinceLastPromotion'].astype(int)\n",
    "hr_data['YearsWithCurrManager'] = hr_data['YearsWithCurrManager'].astype(int)\n",
    "hr_data['JobInvolvement'] = hr_data['JobInvolvement'].astype('category')\n",
    "hr_data['PerformanceRating'] = hr_data['PerformanceRating'].astype('category')\n",
    "hr_data['EnvironmentSatisfaction'] = hr_data['EnvironmentSatisfaction'].astype('category')\n",
    "hr_data['JobSatisfaction'] = hr_data['JobSatisfaction'].astype('category')\n",
    "hr_data['WorkLifeBalance'] = hr_data['WorkLifeBalance'].astype('category')\n",
    "\n",
    "# Sauvegarder les données fusionnées\n",
    "hr_data.to_csv('merged_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification du type de chaque colonne\n",
    "#print(hr_data.dtypes)\n",
    "\n",
    "# Voir les donnees manquantes\n",
    "#print(hr_data.isnull().sum())\n",
    "#print(survey_data.isnull().sum())\n",
    "#print(manager_data.isnull().sum())\n",
    "# Normalisation des données\n",
    "categorical_columns = ['Departement', 'EducationField', 'JobRole']\n",
    "binary_columns = ['Attrition', 'Gender']\n",
    "numerical_columns = hr_data.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "numerical_columns = [col for col in numerical_columns if col not in categorical_columns + binary_columns]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "hr_data[numerical_columns] = scaler.fit_transform(hr_data[numerical_columns])\n",
    "\n",
    "hr_data.to_csv('merged_data_normalized.csv', index=False)\n",
    "\n",
    "print(hr_data.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify missing values directly for in_time and out_time (excluding EmployeeID column)\n",
    "absence_status = (in_time_data.iloc[:, 1:].isna() | out_time_data.iloc[:, 1:].isna())\n",
    "\n",
    "# Find rest days (both in_time and out_time are missing)\n",
    "# Drop rows where both in_time and out_time are missing for all employees (rest days)\n",
    "absence_status = absence_status.dropna(axis=0, how='all')\n",
    "\n",
    "# Convert boolean values to 'Absent' and 'Present'\n",
    "absence_status = absence_status.replace({True: 'Absent', False: 'Present'})\n",
    "\n",
    "# Insert EmployeeID column to retain it (from in_time_data)\n",
    "absence_status.insert(0, 'EmployeeID', in_time_data['EmployeeID'])\n",
    "\n",
    "# Check if EmployeeID column only contains one unique value (like 'True')\n",
    "if absence_status.iloc[:, 0].value_counts().size == 1:\n",
    "    absence_status = absence_status.drop(columns=['EmployeeID'])\n",
    "\n",
    "# Save absenteeism DataFrame to a CSV\n",
    "absence_status.to_csv('absence_status.csv', index=False)\n",
    "\n",
    "# Count the number of 'Absent' days for each employee\n",
    "absence_days = absence_status.iloc[:, 1:].apply(lambda x: (x == 'Absent').sum(), axis=1)\n",
    "\n",
    "# Add EmployeeID column to the absenteeism counts\n",
    "absence_days = pd.DataFrame({\n",
    "    'EmployeeID': absence_status['EmployeeID'] if 'EmployeeID' in absence_status.columns else [],\n",
    "    'AbsenceDays': absence_days\n",
    "})\n",
    "\n",
    "# Save the number of absence days to a CSV file\n",
    "absence_days.to_csv('absence_days.csv', index=False)\n",
    "\n",
    "# Calculate and display the mean number of absence days\n",
    "mean_absence_days = absence_days['AbsenceDays'].mean()\n",
    "print(f\"Mean number of absence days: {mean_absence_days}\")\n",
    "\n",
    "# Additional Stats:\n",
    "# 1. Total Absences in the Company\n",
    "total_absences = absence_days['AbsenceDays'].sum()\n",
    "print(f\"Total Absences in the Company: {total_absences}\")\n",
    "\n",
    "# 2. Percentage of Absence Days for each Employee\n",
    "absence_days['AbsencePercentage'] = (absence_days['AbsenceDays'] / (absence_status.shape[1] - 1)) * 100  # excluding EmployeeID column\n",
    "print(absence_days[['EmployeeID', 'AbsencePercentage']].head())\n",
    "\n",
    "# 3. Employee with the Most Absences\n",
    "max_absences_employee = absence_days.loc[absence_days['AbsenceDays'].idxmax()]\n",
    "print(f\"Employee with Most Absences: {max_absences_employee['EmployeeID']} with {max_absences_employee['AbsenceDays']} absences\")\n",
    "\n",
    "# 4. Employee with the Least Absences\n",
    "min_absences_employee = absence_days.loc[absence_days['AbsenceDays'].idxmin()]\n",
    "print(f\"Employee with Least Absences: {min_absences_employee['EmployeeID']} with {min_absences_employee['AbsenceDays']} absences\")\n",
    "\n",
    "# 5. Mean, Median, Mode of Absence Days\n",
    "median_absence_days = absence_days['AbsenceDays'].median()\n",
    "mode_absence_days = absence_days['AbsenceDays'].mode()[0]  # If there is a mode, it returns the most frequent value\n",
    "\n",
    "print(f\"Median Number of Absence Days: {median_absence_days}\")\n",
    "print(f\"Mode of Absence Days: {mode_absence_days}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse univariée\n",
    "# Afficher les répartitions des données\n",
    "\n",
    "import pandas as pd\n",
    "# enlever les warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Charger les données fusionnées\n",
    "hr_data = pd.read_csv('merged_data.csv')\n",
    "\n",
    "# Créer un dictionnaire pour stocker les statistiques\n",
    "statistics = []\n",
    "\n",
    "# Calculer les statistiques pour chaque colonne\n",
    "def calculate_statistics(data, statistics):\n",
    "    for column in data.columns:\n",
    "        col_data = data[column]\n",
    "        if col_data.dtypes == 'object':  # Colonnes catégorielles\n",
    "            value_counts = col_data.value_counts().to_dict()\n",
    "            statistics.append({\n",
    "                'Column': column,\n",
    "                'Type': 'Categorical',\n",
    "                'Value Counts': value_counts\n",
    "            })\n",
    "        else:  # Colonnes numériques\n",
    "            statistics.append({\n",
    "                'Column': column,\n",
    "                'Type': 'Numeric',\n",
    "                'Mean': col_data.mean(),\n",
    "                'Median': col_data.median(),\n",
    "                'StdDev': col_data.std(),\n",
    "                'Min': col_data.min(),\n",
    "                'Max': col_data.max(),\n",
    "                'Unique Values': col_data.nunique()\n",
    "            })\n",
    "\n",
    "# Appeler la fonction de calcul des statistiques\n",
    "calculate_statistics(hr_data, statistics)\n",
    "\n",
    "# Convertir les statistiques en DataFrame pour l'export\n",
    "statistics_df = pd.DataFrame(statistics)\n",
    "\n",
    "# Sauvegarder les statistiques dans un fichier CSV\n",
    "statistics_df.to_csv('statistics-data.csv', index=False)\n",
    "\n",
    "# Afficher les statistiques dans la console\n",
    "# print(statistics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caractéristiques des employés qui ont quitté l'entreprise\n",
    "# Séparer les employés ayant quitté l'entreprise\n",
    "attrition_yes = hr_data[hr_data['Attrition'] == 'Yes']\n",
    "# Calculer les statistiques pour les employés ayant quitté l'entreprise\n",
    "statistics_attrition = []\n",
    "calculate_statistics(attrition_yes, statistics_attrition)\n",
    "statistics_attrition_df = pd.DataFrame(statistics_attrition)\n",
    "statistics_attrition_df.to_csv('statistics-attrition.csv', index=False)\n",
    "#print(statistics_attrition_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELE DE PREDICTION\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_env)",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
